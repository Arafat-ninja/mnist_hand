import tensorflow as tfimport  numpy as npdatapath  = r'mnist.npz'(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(datapath)#读取数据集  keras是接口x_train = tf.keras.utils.normalize(x_train, axis=1)#划分训练集x_test = tf.keras.utils.normalize(x_test, axis=1)#划分测试集#构建模型model = tf.keras.models.Sequential()model.add(tf.keras.layers.Flatten())model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))model.add(tf.keras.layers.Dropout(0.3))model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))#编译模型model.compile(optimizer='adam',          #优化器，adam算法              loss='sparse_categorical_crossentropy',   #损失函数              metrics=['accuracy'])#开始训练model.fit(x_train, y_train, epochs=30)model.save('Mnist.h5')                      #储存训练模型#测试模型val_loss, val_acc = model.evaluate(x_test, y_test)print(val_loss)print(val_acc)